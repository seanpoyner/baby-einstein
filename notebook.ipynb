{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baby Einstein \n",
    "# Version: Albert:0.0.1\n",
    "\n",
    "# Install required packages\n",
    "%pip install -r requirements.txt > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import json\n",
    "import requests\n",
    "import urllib3\n",
    "import base64\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable insecure request warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionClient:\n",
    "    def __init__(self, model: str, url: str = \"https://typingmind.poyner.lan/v1/chat/completions\"):\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "\n",
    "    def analyze_image(self, image_path: str) -> requests.Response:\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "            encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {image_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Modified payload to include the messages field\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Short caption: {encoded_image}\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        return requests.post(self.url, json=payload, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client instance and analyze image\n",
    "client = VisionClient(model=\"moondream\")\n",
    "result = client.analyze_image(\"/home/sean/baby-einstein/examples/sight/eagle.jpg\")\n",
    "print(\"Analysis Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ChatClient class\n",
    "# Since we are structuring these thoughts and loops in json format, we can use the ChatClient class to interact with the chat completion API.\n",
    "# This class will ensure that the structure of the requests is correct and that the responses are parsed correctly.\n",
    "\n",
    "class ChatClient:\n",
    "    \"\"\"A base client for interacting with the chat completion API.\"\"\"\n",
    "    # Here I am using a local device (typingmind) on my network (poyner.lan) to run the model using ollama. The repository is hosted on this device and models are loaded from Modelfiles there.\n",
    "    def __init__(self, model: str, url: str = \"https://typingmind.poyner.lan/v1/chat/completions\"):\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "\n",
    "# The send_message method sends a message to the chat completion API and returns the response.\n",
    "    def send_message(self, message: str) -> str:\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": message}\n",
    "            ]\n",
    "        }\n",
    "        response = requests.post(self.url, json=payload, verify=False)\n",
    "        \n",
    "# The response is parsed and the content of the first choice is returned.\n",
    "        try:\n",
    "            data = response.json()\n",
    "            choices = data.get(\"choices\", [])\n",
    "            if not choices:\n",
    "                raise ValueError(\"No choices available in response: \" + str(data))\n",
    "            content = choices[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return content\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Response is not in JSON format: \" + response.text) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ThalamusClient class\n",
    "# The ThalamusClient class is a subclass of ChatClient that is specialized for sending analysis requests to the Thalamus model.\n",
    "# The Thalamus model is the central processing unit of the Baby Einstein system, responsible for analyzing sensor data and routing it to the appropriate models for further processing.\n",
    "class ThalamusClient(ChatClient):\n",
    "    \"\"\"Client for sending analysis requests to the Thalamus model.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(model=\"baby-einstein/thalamus:latest\")\n",
    "\n",
    "# The analyze method sends an analysis request to the Thalamus model and returns the response.\n",
    "    def analyze(self, sensor: str, input_type: str, input_data: str, threshold_score: str) -> str:\n",
    "        inner_message = json.dumps({\n",
    "            \"sensor\": sensor,\n",
    "            \"input_type\": input_type,\n",
    "            \"input_data\": input_data,\n",
    "            \"threshold_score\": threshold_score\n",
    "        })\n",
    "        return self.send_message(inner_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ACCClient class\n",
    "# The ACCClient class is a subclass of ChatClient that is specialized for sending evaluation requests to the ACC model.\n",
    "# The ACC model is responsible for evaluating the output of the Thalamus model and determining if it meets the criteria for further processing or needs to be returned to the thalamus.\n",
    "class ACCClient(ChatClient):\n",
    "    \"\"\"Client for sending evaluation requests to the ACC model.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(model=\"baby-einstein/acc:latest\")\n",
    "\n",
    "# The evaluate method sends an evaluation request to the ACC model and returns the response.\n",
    "    def evaluate(self, thalamus_output: str) -> str:\n",
    "        return self.send_message(thalamus_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input parameters\n",
    "sensor = \"camera\"\n",
    "input_type = \"image\"\n",
    "input_data = \"object moving in front of camera\"\n",
    "threshold_score = \".88\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ThalamusClient instance and get its response\n",
    "thalamus_client = ThalamusClient()\n",
    "thalamus_response = thalamus_client.analyze(sensor, input_type, input_data, threshold_score)\n",
    "print(\"Thalamus response:\")\n",
    "print(thalamus_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ACCClient instance and evaluate the Thalamus response\n",
    "acc_client = ACCClient()\n",
    "acc_response = acc_client.evaluate(thalamus_response)\n",
    "print(\"ACC response:\")\n",
    "print(acc_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 (baby-einstein .env)",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
