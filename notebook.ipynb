{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Baby Einstein \n",
    "# Version: Albert:0.0.1\n",
    "\n",
    "# Install required packages\n",
    "%pip install -r requirements.txt > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#import urllib3\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbase64\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import json\n",
    "import requests\n",
    "#import urllib3\n",
    "import base64\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable insecure request warnings\n",
    "#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SightClient:\n",
    "    def __init__(self, model: str, url: str = \"https://typingmind.poyner.lan/v1/chat/completions\"):\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "\n",
    "    def resize_image(self, image_path: str, output_path: str, max_size=(800, 800)):\n",
    "        with Image.open(image_path) as img:\n",
    "            img.thumbnail(max_size)  # Resize image while maintaining aspect ratio\n",
    "            img.save(output_path)  # Save the resized image\n",
    "\n",
    "    def analyze_image(self, image_path: str) -> str:\n",
    "        # Create a temporary resized image file\n",
    "        resized_image_path = image_path.replace('.jpg', '_resized.jpg')  # Change extension if needed\n",
    "        self.resize_image(image_path, resized_image_path)\n",
    "\n",
    "        try:\n",
    "            with open(resized_image_path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "            encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {resized_image_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Modified payload to include the messages field\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Analyze this image and provide a JSON response with input_data and threshold_score. Here's the data: {encoded_image}\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        print(\"DEBUG: Sending request to:\", self.url)\n",
    "        print(\"DEBUG: Request payload structure:\", json.dumps(payload, indent=2))\n",
    "\n",
    "        response = requests.post(self.url, json=payload, verify=False)\n",
    "\n",
    "        print(\"DEBUG: Response status code:\", response.status_code)\n",
    "        print(\"DEBUG: Response headers:\", dict(response.headers))\n",
    "        print(\"DEBUG: Raw response text:\", response.text)\n",
    "\n",
    "        try:\n",
    "            data = response.json()\n",
    "            # Adjust response parsing according to the expected output\n",
    "            if 'choices' in data and len(data['choices']) > 0 and 'message' in data['choices'][0]:\n",
    "                return data['choices'][0]['message']['content']\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected response format: \" + str(data))\n",
    "        except ValueError as e:\n",
    "            raise ValueError(f\"Response is not in JSON format. Status: {response.status_code}, Text: {response.text}\") from e\n",
    "\n",
    "# Create client instance and analyze image\n",
    "client = SightClient(model=\"baby-einstein/vision/sight:latest\")\n",
    "result = client.analyze_image(\"/home/sean/baby-einstein/examples/sight/eagle.jpg\")\n",
    "print(\"Analysis Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ChatClient class\n",
    "# Since we are structuring these thoughts and loops in json format, we can use the ChatClient class to interact with the chat completion API.\n",
    "# This class will ensure that the structure of the requests is correct and that the responses are parsed correctly.\n",
    "\n",
    "class ChatClient:\n",
    "    \"\"\"A base client for interacting with the chat completion API.\"\"\"\n",
    "    # Here I am using a local device (typingmind) on my network (poyner.lan) to run the model using ollama. The repository is hosted on this device and models are loaded from Modelfiles there.\n",
    "    def __init__(self, model: str, url: str = \"https://typingmind.poyner.lan/v1/chat/completions\"):\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "\n",
    "# The send_message method sends a message to the chat completion API and returns the response.\n",
    "    def send_message(self, message: str) -> str:\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": message}\n",
    "            ]\n",
    "        }\n",
    "        response = requests.post(self.url, json=payload, verify=False)\n",
    "        \n",
    "# The response is parsed and the content of the first choice is returned.\n",
    "        try:\n",
    "            data = response.json()\n",
    "            choices = data.get(\"choices\", [])\n",
    "            if not choices:\n",
    "                raise ValueError(\"No choices available in response: \" + str(data))\n",
    "            content = choices[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return content\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Response is not in JSON format: \" + response.text) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ThalamusClient class\n",
    "# The ThalamusClient class is a subclass of ChatClient that is specialized for sending analysis requests to the Thalamus model.\n",
    "# The Thalamus model is the central processing unit of the Baby Einstein system, responsible for analyzing sensor data and routing it to the appropriate models for further processing.\n",
    "class ThalamusClient(ChatClient):\n",
    "    \"\"\"Client for sending analysis requests to the Thalamus model.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(model=\"baby-einstein/thalamus:latest\")\n",
    "\n",
    "# The analyze method sends an analysis request to the Thalamus model and returns the response.\n",
    "    def analyze(self, sensor: str, input_type: str, input_data: str, threshold_score: str) -> str:\n",
    "        inner_message = json.dumps({\n",
    "            \"sensor\": sensor,\n",
    "            \"input_type\": input_type,\n",
    "            \"input_data\": input_data,\n",
    "            \"threshold_score\": threshold_score\n",
    "        })\n",
    "        return self.send_message(inner_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ACCClient class\n",
    "# The ACCClient class is a subclass of ChatClient that is specialized for sending evaluation requests to the ACC model.\n",
    "# The ACC model is responsible for evaluating the output of the Thalamus model and determining if it meets the criteria for further processing or needs to be returned to the thalamus.\n",
    "class ACCClient(ChatClient):\n",
    "    \"\"\"Client for sending evaluation requests to the ACC model.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(model=\"baby-einstein/acc:latest\")\n",
    "\n",
    "# The evaluate method sends an evaluation request to the ACC model and returns the response.\n",
    "    def evaluate(self, thalamus_output: str) -> str:\n",
    "        return self.send_message(thalamus_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input parameters\n",
    "sensor = \"camera\"\n",
    "input_type = \"image\"\n",
    "input_data = \"object moving in front of camera\"\n",
    "threshold_score = \".88\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ThalamusClient instance and get its response\n",
    "thalamus_client = ThalamusClient()\n",
    "thalamus_response = thalamus_client.analyze(sensor, input_type, input_data, threshold_score)\n",
    "print(\"Thalamus response:\")\n",
    "print(thalamus_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ACCClient instance and evaluate the Thalamus response\n",
    "acc_client = ACCClient()\n",
    "acc_response = acc_client.evaluate(thalamus_response)\n",
    "print(\"ACC response:\")\n",
    "print(acc_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 (baby-einstein .env)",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
